{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement batch gradient descent with early stopping for softmax\n",
    "regression without using Scikit-Learn, only NumPy. Use it on a\n",
    "classification task such as the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'target',\n",
       " 'frame',\n",
       " 'target_names',\n",
       " 'DESCR',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'data_module']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "list(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X = iris.data[['petal length (cm)', 'petal width (cm)']].values\n",
    "y = iris['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bias (x_0 = 1) to every instance\n",
    "import numpy as np\n",
    "\n",
    "X_with_bias = np.c_[np.ones(len(X)), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "validation_ratio = 0.2\n",
    "total_size = len(X_with_bias)\n",
    "\n",
    "test_size = int(total_size * test_ratio)\n",
    "validation_size = int(total_size * validation_ratio)\n",
    "train_size = total_size - test_size - validation_size\n",
    "\n",
    "np.random.seed(42)\n",
    "rnd_indices = np.random.permutation(total_size)\n",
    "\n",
    "X_train = X_with_bias[rnd_indices[:train_size]]\n",
    "y_train = y[rnd_indices[:train_size]]\n",
    "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
    "y_valid = y[rnd_indices[train_size:-test_size]]\n",
    "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
    "y_test = y[rnd_indices[-test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y):\n",
    "    return np.diag(np.ones(y.max() + 1))[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_one_hot = to_one_hot(y_train)\n",
    "Y_valid_one_hot = to_one_hot(y_valid)\n",
    "Y_test_one_hot = to_one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train[:, 1:].mean(axis=0)\n",
    "std = X_train[:, 1:].std(axis=0)\n",
    "X_train[:, 1:] = (X_train[:, 1:] - mean) / std\n",
    "X_valid[:, 1:] = (X_valid[:, 1:] - mean) / std\n",
    "X_test[:, 1:] = (X_test[:, 1:] - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    exps = np.exp(logits)\n",
    "    exp_sums = exps.sum(axis=1, keepdims=True)\n",
    "    return exps / exp_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1]  # == 3 (2 features plus the bias term)\n",
    "n_outputs = len(np.unique(y_train))  # == 3 (there are 3 iris classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.7085808486476917\n",
      "1000 0.14519367480830644\n",
      "2000 0.1301309575504088\n",
      "3000 0.12009639326384539\n",
      "4000 0.11372961364786884\n",
      "5000 0.11002459532472425\n"
     ]
    }
   ],
   "source": [
    "eta = 0.5\n",
    "n_epochs = 5001\n",
    "m = len(X_train)\n",
    "epsilon = 1e-5\n",
    "\n",
    "np.random.seed(42)\n",
    "Theta = np.random.randn(n_inputs, n_outputs)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    logits = X_train @ Theta\n",
    "    Y_proba = softmax(logits)\n",
    "    if epoch % 1000 == 0:\n",
    "        Y_proba_valid = softmax(X_valid @ Theta)\n",
    "        xentropy_losses = -(Y_valid_one_hot * np.log(Y_proba_valid + epsilon))\n",
    "        print(epoch, xentropy_losses.sum(axis=1).mean())\n",
    "    error = Y_proba - Y_train_one_hot\n",
    "    gradients = 1 / m * X_train.T @ error\n",
    "    Theta = Theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45010228, 0.13167598, 0.42436013],\n",
       "       [0.17680488, 0.07941275, 0.77758478],\n",
       "       [0.26275942, 0.97616774, 0.60098318]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = X_valid @ Theta\n",
    "Y_proba = softmax(logits)\n",
    "y_predict = Y_proba.argmax(axis=1)\n",
    "\n",
    "accuracy_score = (y_predict == y_valid).mean()\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
